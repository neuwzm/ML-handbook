周志华《机器学习》



第一章：绪论



根据训练数据是否拥有标记信息，学习任务可以大致分为两大类：监督学习（supervised learning）、无监督学习（unsupervised learning），分类和回归是前者的代表、而聚类是后者的代表。



学得模型适用于新样本的能力，称为“泛化”能力。



归纳（induction）与演绎（“deduction”）是科学推理的两大基本手段，前者是从特殊到一般的“泛化”过程，即从具体的事实归结出一般性规律，后者则是从一般到特殊的“特化”过程，即从基础原理推演出具体状况。 而“从样例中学习”显然是一个归纳的过程，因此亦称“归纳学习”（inductive learning）



在假设空间中进行搜索，删除与正例不一致的假设、和与反例一致的假设，最终会获得与训练集一致的假设，这就是我们学得的结果。



因为现实问题中会有很大的假设空间，但是在学习过程中我们是基于有限样本训练集进行的，所以会有多个假设与训练集一致，即存在着一个与训练集一致的“假设集合”，我们称之为“版本空间”。



”奥卡姆剃刀“ 是一种常用的、自然科学研究中最基本的原则，即“若有多个假设与观察一致，则选最简单的那个”





第二章：模型评估与选择：



误差：学习器的实际预测输出与样本的真实输出之间的差异



训练误差（经验误差）：学习器在训练集上的误差



泛化误差：学习器在新样本上的误差



过拟合（overfitting）：学习器

欠拟合（underfitting）：对训练样本的一般性质都尚未学好



过拟合是无法彻底避免的，我们能做的只是“缓解”，或者说减少风险。



模型选择：理想的解决方案是对候选模型的泛化误差进行评估，然后选择泛化误差最小的那个模型。

















